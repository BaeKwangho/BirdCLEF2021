{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/zhanghang1989/ResNeSt/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
     ]
    }
   ],
   "source": [
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "import os\n",
    "import librosa\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)\n",
    "\n",
    "df = pd.read_csv('./asset/birdclef-2021/train_metadata.csv')\n",
    "\n",
    "folder_path = './asset/birdclef-2021/train_short_audio/'\n",
    "\n",
    "all_list = list()\n",
    "\n",
    "all_sec = list()\n",
    "for pri,sec,file in zip(df['primary_label'],df['secondary_labels'],df['filename']):\n",
    "    sec_2 = list(sec.replace(\"'\",'').replace('[','').replace(']','').replace(' ','').split(','))  \n",
    "    sec_2.append(pri)\n",
    "    if sec_2[0]=='':\n",
    "        sec_2=sec_2[1:]\n",
    "    for bird in sec_2:\n",
    "        all_sec.append(bird)\n",
    "    filename = os.path.join(folder_path,pri,file)\n",
    "    all_list.append({'path':filename,'bird':sec_2})\n",
    "    \n",
    "blist = list(set(all_sec))\n",
    "classes_num= len(blist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acafly',\n",
       " 'acowoo',\n",
       " 'aldfly',\n",
       " 'ameavo',\n",
       " 'amecro',\n",
       " 'amegfi',\n",
       " 'amekes',\n",
       " 'amepip',\n",
       " 'amered',\n",
       " 'amerob',\n",
       " 'amewig',\n",
       " 'amtspa',\n",
       " 'andsol1',\n",
       " 'annhum',\n",
       " 'astfly',\n",
       " 'azaspi1',\n",
       " 'babwar',\n",
       " 'baleag',\n",
       " 'balori',\n",
       " 'banana',\n",
       " 'banswa',\n",
       " 'banwre1',\n",
       " 'barant1',\n",
       " 'barswa',\n",
       " 'batpig1',\n",
       " 'bawswa1',\n",
       " 'bawwar',\n",
       " 'baywre1',\n",
       " 'bbwduc',\n",
       " 'bcnher',\n",
       " 'belkin1',\n",
       " 'belvir',\n",
       " 'bewwre',\n",
       " 'bkbmag1',\n",
       " 'bkbplo',\n",
       " 'bkbwar',\n",
       " 'bkcchi',\n",
       " 'bkhgro',\n",
       " 'bkmtou1',\n",
       " 'bknsti',\n",
       " 'blbgra1',\n",
       " 'blbthr1',\n",
       " 'blcjay1',\n",
       " 'blctan1',\n",
       " 'blhpar1',\n",
       " 'blkpho',\n",
       " 'blsspa1',\n",
       " 'blugrb1',\n",
       " 'blujay',\n",
       " 'bncfly',\n",
       " 'bnhcow',\n",
       " 'bobfly1',\n",
       " 'bongul',\n",
       " 'botgra',\n",
       " 'brbmot1',\n",
       " 'brbsol1',\n",
       " 'brcvir1',\n",
       " 'brebla',\n",
       " 'brncre',\n",
       " 'brnjay',\n",
       " 'brnthr',\n",
       " 'brratt1',\n",
       " 'brwhaw',\n",
       " 'brwpar1',\n",
       " 'btbwar',\n",
       " 'btnwar',\n",
       " 'btywar',\n",
       " 'bucmot2',\n",
       " 'buggna',\n",
       " 'bugtan',\n",
       " 'buhvir',\n",
       " 'bulori',\n",
       " 'burwar1',\n",
       " 'bushti',\n",
       " 'butsal1',\n",
       " 'buwtea',\n",
       " 'cacgoo1',\n",
       " 'cacwre',\n",
       " 'calqua',\n",
       " 'caltow',\n",
       " 'cangoo',\n",
       " 'canwar',\n",
       " 'carchi',\n",
       " 'carwre',\n",
       " 'casfin',\n",
       " 'caskin',\n",
       " 'caster1',\n",
       " 'casvir',\n",
       " 'categr',\n",
       " 'ccbfin',\n",
       " 'cedwax',\n",
       " 'chbant1',\n",
       " 'chbchi',\n",
       " 'chbwre1',\n",
       " 'chcant2',\n",
       " 'chispa',\n",
       " 'chswar',\n",
       " 'cinfly2',\n",
       " 'clanut',\n",
       " 'clcrob',\n",
       " 'cliswa',\n",
       " 'cobtan1',\n",
       " 'cocwoo1',\n",
       " 'cogdov',\n",
       " 'colcha1',\n",
       " 'coltro1',\n",
       " 'comgol',\n",
       " 'comgra',\n",
       " 'comloo',\n",
       " 'commer',\n",
       " 'compau',\n",
       " 'compot1',\n",
       " 'comrav',\n",
       " 'comyel',\n",
       " 'coohaw',\n",
       " 'cotfly1',\n",
       " 'cowscj1',\n",
       " 'cregua1',\n",
       " 'creoro1',\n",
       " 'crfpar',\n",
       " 'cubthr',\n",
       " 'daejun',\n",
       " 'dowwoo',\n",
       " 'ducfly',\n",
       " 'dusfly',\n",
       " 'easblu',\n",
       " 'easkin',\n",
       " 'easmea',\n",
       " 'easpho',\n",
       " 'eastow',\n",
       " 'eawpew',\n",
       " 'eletro',\n",
       " 'eucdov',\n",
       " 'eursta',\n",
       " 'fepowl',\n",
       " 'fiespa',\n",
       " 'flrtan1',\n",
       " 'foxspa',\n",
       " 'gadwal',\n",
       " 'gamqua',\n",
       " 'gartro1',\n",
       " 'gbbgul',\n",
       " 'gbwwre1',\n",
       " 'gcrwar',\n",
       " 'gilwoo',\n",
       " 'gnttow',\n",
       " 'gnwtea',\n",
       " 'gocfly1',\n",
       " 'gockin',\n",
       " 'gocspa',\n",
       " 'goftyr1',\n",
       " 'gohque1',\n",
       " 'goowoo1',\n",
       " 'grasal1',\n",
       " 'grbani',\n",
       " 'grbher3',\n",
       " 'grcfly',\n",
       " 'greegr',\n",
       " 'grekis',\n",
       " 'grepew',\n",
       " 'grethr1',\n",
       " 'gretin1',\n",
       " 'greyel',\n",
       " 'grhcha1',\n",
       " 'grhowl',\n",
       " 'grnher',\n",
       " 'grnjay',\n",
       " 'grtgra',\n",
       " 'grycat',\n",
       " 'gryhaw2',\n",
       " 'gwfgoo',\n",
       " 'haiwoo',\n",
       " 'heptan',\n",
       " 'hergul',\n",
       " 'herthr',\n",
       " 'herwar',\n",
       " 'higmot1',\n",
       " 'hofwoo1',\n",
       " 'houfin',\n",
       " 'houspa',\n",
       " 'houwre',\n",
       " 'hutvir',\n",
       " 'incdov',\n",
       " 'indbun',\n",
       " 'kebtou1',\n",
       " 'killde',\n",
       " 'labwoo',\n",
       " 'larspa',\n",
       " 'laufal1',\n",
       " 'laugul',\n",
       " 'lazbun',\n",
       " 'leafly',\n",
       " 'leasan',\n",
       " 'lesgol',\n",
       " 'lesgre1',\n",
       " 'lesvio1',\n",
       " 'linspa',\n",
       " 'linwoo1',\n",
       " 'littin1',\n",
       " 'lobdow',\n",
       " 'lobgna5',\n",
       " 'logshr',\n",
       " 'lotduc',\n",
       " 'lotman1',\n",
       " 'lucwar',\n",
       " 'macwar',\n",
       " 'magwar',\n",
       " 'mallar3',\n",
       " 'marwre',\n",
       " 'mastro1',\n",
       " 'meapar',\n",
       " 'melbla1',\n",
       " 'monoro1',\n",
       " 'mouchi',\n",
       " 'moudov',\n",
       " 'mouela1',\n",
       " 'mouqua',\n",
       " 'mouwar',\n",
       " 'mutswa',\n",
       " 'naswar',\n",
       " 'norcar',\n",
       " 'norfli',\n",
       " 'normoc',\n",
       " 'norpar',\n",
       " 'norsho',\n",
       " 'norwat',\n",
       " 'nrwswa',\n",
       " 'nutwoo',\n",
       " 'oaktit',\n",
       " 'obnthr1',\n",
       " 'ocbfly1',\n",
       " 'oliwoo1',\n",
       " 'olsfly',\n",
       " 'orbeup1',\n",
       " 'orbspa1',\n",
       " 'orcpar',\n",
       " 'orcwar',\n",
       " 'orfpar',\n",
       " 'osprey',\n",
       " 'ovenbi1',\n",
       " 'pabspi1',\n",
       " 'paltan1',\n",
       " 'palwar',\n",
       " 'pasfly',\n",
       " 'pavpig2',\n",
       " 'phivir',\n",
       " 'pibgre',\n",
       " 'pilwoo',\n",
       " 'pinsis',\n",
       " 'pirfly1',\n",
       " 'plawre1',\n",
       " 'plaxen1',\n",
       " 'plsvir',\n",
       " 'plupig2',\n",
       " 'prowar',\n",
       " 'purfin',\n",
       " 'purgal2',\n",
       " 'putfru1',\n",
       " 'pygnut',\n",
       " 'rawwre1',\n",
       " 'rcatan1',\n",
       " 'rebnut',\n",
       " 'rebsap',\n",
       " 'rebwoo',\n",
       " 'redcro',\n",
       " 'reevir1',\n",
       " 'rehbar1',\n",
       " 'relpar',\n",
       " 'reshaw',\n",
       " 'rethaw',\n",
       " 'rewbla',\n",
       " 'ribgul',\n",
       " 'rinkin1',\n",
       " 'roahaw',\n",
       " 'robgro',\n",
       " 'rocpig',\n",
       " 'rocpig1',\n",
       " 'rotbec',\n",
       " 'royter1',\n",
       " 'rthhum',\n",
       " 'rtlhum',\n",
       " 'ruboro1',\n",
       " 'rubpep1',\n",
       " 'rubrob',\n",
       " 'rubwre1',\n",
       " 'ruckin',\n",
       " 'rucspa1',\n",
       " 'rucwar',\n",
       " 'rucwar1',\n",
       " 'rudpig',\n",
       " 'rudtur',\n",
       " 'rufhum',\n",
       " 'rugdov',\n",
       " 'rumfly1',\n",
       " 'runwre1',\n",
       " 'rutjac1',\n",
       " 'saffin',\n",
       " 'sancra',\n",
       " 'sander',\n",
       " 'savspa',\n",
       " 'saypho',\n",
       " 'scamac1',\n",
       " 'scatan',\n",
       " 'scbwre1',\n",
       " 'scptyr1',\n",
       " 'scrtan1',\n",
       " 'semplo',\n",
       " 'shicow',\n",
       " 'sibtan2',\n",
       " 'sinwre1',\n",
       " 'sltred',\n",
       " 'smbani',\n",
       " 'snogoo',\n",
       " 'sobtyr1',\n",
       " 'socfly1',\n",
       " 'solsan',\n",
       " 'sonspa',\n",
       " 'soulap1',\n",
       " 'sposan',\n",
       " 'spotow',\n",
       " 'spvear1',\n",
       " 'squcuc1',\n",
       " 'stbori',\n",
       " 'stejay',\n",
       " 'sthant1',\n",
       " 'sthwoo1',\n",
       " 'strcuc1',\n",
       " 'strfly1',\n",
       " 'strsal1',\n",
       " 'stvhum2',\n",
       " 'subfly',\n",
       " 'sumtan',\n",
       " 'swaspa',\n",
       " 'swathr',\n",
       " 'tenwar',\n",
       " 'thbeup1',\n",
       " 'thbkin',\n",
       " 'thswar1',\n",
       " 'towsol',\n",
       " 'treswa',\n",
       " 'trogna1',\n",
       " 'trokin',\n",
       " 'tromoc',\n",
       " 'tropar',\n",
       " 'tropew1',\n",
       " 'tuftit',\n",
       " 'tunswa',\n",
       " 'veery',\n",
       " 'verdin',\n",
       " 'vigswa',\n",
       " 'warvir',\n",
       " 'wbwwre1',\n",
       " 'webwoo1',\n",
       " 'wegspa1',\n",
       " 'wesant1',\n",
       " 'wesblu',\n",
       " 'weskin',\n",
       " 'wesmea',\n",
       " 'westan',\n",
       " 'wewpew',\n",
       " 'whbman1',\n",
       " 'whbnut',\n",
       " 'whcpar',\n",
       " 'whcsee1',\n",
       " 'whcspa',\n",
       " 'whevir',\n",
       " 'whfpar1',\n",
       " 'whimbr',\n",
       " 'whiwre1',\n",
       " 'whtdov',\n",
       " 'whtspa',\n",
       " 'whwbec1',\n",
       " 'whwdov',\n",
       " 'wilfly',\n",
       " 'willet1',\n",
       " 'wilsni1',\n",
       " 'wiltur',\n",
       " 'wlswar',\n",
       " 'wooduc',\n",
       " 'woothr',\n",
       " 'wrenti',\n",
       " 'y00475',\n",
       " 'yebcha',\n",
       " 'yebela1',\n",
       " 'yebfly',\n",
       " 'yebori1',\n",
       " 'yebsap',\n",
       " 'yebsee1',\n",
       " 'yefgra1',\n",
       " 'yegvir',\n",
       " 'yehbla',\n",
       " 'yehcar1',\n",
       " 'yelgro',\n",
       " 'yelwar',\n",
       " 'yeofly1',\n",
       " 'yerwar',\n",
       " 'yeteup1',\n",
       " 'yetvir'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepareing\n",
    "import random\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import soundfile as sf\n",
    "\n",
    "df = pd.read_csv('./asset/birdclef-2021/train_metadata.csv')\n",
    "\n",
    "folder_path = './asset/birdclef-2021/train_short_audio/'\n",
    "\n",
    "all_list = list()\n",
    "\n",
    "all_sec = list()\n",
    "for pri,sec,file in zip(df['primary_label'],df['secondary_labels'],df['filename']):\n",
    "    sec_2 = list(sec.replace(\"'\",'').replace('[','').replace(']','').replace(' ','').split(','))  \n",
    "    sec_2.append(pri)\n",
    "    if sec_2[0]=='':\n",
    "        sec_2=sec_2[1:]\n",
    "    for bird in sec_2:\n",
    "        all_sec.append(bird)\n",
    "    filename = os.path.join(folder_path,pri,file)\n",
    "    all_list.append({'path':filename,'bird':sec_2})\n",
    "\n",
    "class testData(Dataset):\n",
    "    def __init__(self,all_list):\n",
    "        self.all_list = all_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_list)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.all_list[idx]\n",
    "    \n",
    "blist = list(set(all_sec))\n",
    "classes_num= len(blist)\n",
    "\n",
    "# collate_fn by class type, handling with parameters/frame\n",
    "'''\n",
    "class Collator(object):\n",
    "    def __init__(self,blist,frame_sec=7,sr=32000,number_of_frame=20,classes_num=397):\n",
    "        self.frame_sec = frame_sec\n",
    "        self.sr = sr\n",
    "        self.number_of_frame = number_of_frame\n",
    "        self.classes_num = classes_num\n",
    "        self.blist = blist\n",
    "        \n",
    "    def __call__(self,batch):\n",
    "        birds = list()\n",
    "        frames = list()\n",
    "        duration = self.frame_sec * self.sr\n",
    "        \n",
    "        batch_ind = 0\n",
    "        wav, _ = librosa.load(batch[batch_ind]['path'],sr=32000)\n",
    "        \n",
    "        wav_ind = 0\n",
    "        while len(frames) < self.number_of_frame:\n",
    "            if wav_ind+duration>len(wav) and batch_ind<len(batch)-1:\n",
    "                batch_ind += 1\n",
    "                wav, _ = librosa.load(batch[batch_ind]['path'],sr=32000)\n",
    "                wav_ind = 0\n",
    "            else:\n",
    "                frame = wav[wav_ind:wav_ind+duration]\n",
    "                frames.append(frame[np.newaxis])\n",
    "                \n",
    "                bird_arr = np.zeros((1,self.classes_num))\n",
    "                for bird in batch[batch_ind]['bird']:\n",
    "                    bird_arr[0][self.blist.index(bird)]=1\n",
    "                    birds.append(bird_arr)\n",
    "                wav_ind += duration\n",
    "                \n",
    "        print(frames)\n",
    "        frames = np.concatenate(frames)\n",
    "        birds = np.concatenate(birds)\n",
    "        \n",
    "        return frames,birds\n",
    "'''\n",
    "class BCEFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n",
    "        probas = torch.sigmoid(preds)\n",
    "        loss = targets * self.alpha * \\\n",
    "            (1. - probas)**self.gamma * bce_loss + \\\n",
    "            (1. - targets) * probas**self.gamma * bce_loss\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class BCEFocal2WayLoss(nn.Module):\n",
    "    def __init__(self, weights=[1, 1], class_weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.focal = BCEFocalLoss()\n",
    "\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"logit\"]\n",
    "        target = target.float()\n",
    "\n",
    "        framewise_output = input[\"framewise_logit\"]\n",
    "        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n",
    "\n",
    "        loss = self.focal(input_, target)\n",
    "        aux_loss = self.focal(clipwise_output_with_max, target)\n",
    "\n",
    "        return self.weights[0] * loss + self.weights[1] * aux_loss\n",
    "    \n",
    "class BatchCollator(object):\n",
    "    def __init__(self,blist,frame_sec=7,sr=32000,classes_num=398):\n",
    "        self.frame_sec = frame_sec\n",
    "        self.sr = sr\n",
    "        self.classes_num = classes_num\n",
    "        self.blist = blist\n",
    "        self.duration = frame_sec * sr\n",
    "\n",
    "    def __call__(self,batch):\n",
    "        waves = list()\n",
    "        birds = np.zeros((len(batch),self.classes_num))\n",
    "        for i,meta in enumerate(batch):\n",
    "            wav, _ = sf.read(meta['path'])\n",
    "            #wav, _ = librosa.load(meta['path'],sr=self.sr)\n",
    "            if len(wav) < self.duration:\n",
    "                wav = np.concatenate([wav,np.zeros((self.duration-len(wav)))])[np.newaxis,:]\n",
    "            else:\n",
    "                ind = random.randint(0,len(wav)-self.duration)\n",
    "                wav = wav[ind:ind+self.duration][np.newaxis,:]\n",
    "            waves.append(wav)\n",
    "            for bird in meta['bird']:\n",
    "                birds[i][blist.index(bird)] = 1\n",
    "\n",
    "        waves = np.concatenate(waves)\n",
    "\n",
    "        return waves,birds\n",
    "\n",
    "dataset = testData(all_list)\n",
    "collator = BatchCollator(blist)\n",
    "#dataloader = DataLoader(dataset,batch_size=1,shuffle=True,collate_fn=make_batch)\n",
    "dataloader = DataLoader(dataset,batch_size=20,shuffle=True,collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    " \n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "    \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "\n",
    "\n",
    "def init_gru(rnn):\n",
    "    \"\"\"Initialize a GRU layer. \"\"\"\n",
    "    \n",
    "    def _concat_init(tensor, init_funcs):\n",
    "        (length, fan_out) = tensor.shape\n",
    "        fan_in = length // len(init_funcs)\n",
    "    \n",
    "        for (i, init_func) in enumerate(init_funcs):\n",
    "            init_func(tensor[i * fan_in : (i + 1) * fan_in, :])\n",
    "        \n",
    "    def _inner_uniform(tensor):\n",
    "        fan_in = nn.init._calculate_correct_fan(tensor, 'fan_in')\n",
    "        nn.init.uniform_(tensor, -math.sqrt(3 / fan_in), math.sqrt(3 / fan_in))\n",
    "    \n",
    "    for i in range(rnn.num_layers):\n",
    "        _concat_init(\n",
    "            getattr(rnn, 'weight_ih_l{}'.format(i)),\n",
    "            [_inner_uniform, _inner_uniform, _inner_uniform]\n",
    "        )\n",
    "        torch.nn.init.constant_(getattr(rnn, 'bias_ih_l{}'.format(i)), 0)\n",
    "\n",
    "        _concat_init(\n",
    "            getattr(rnn, 'weight_hh_l{}'.format(i)),\n",
    "            [_inner_uniform, _inner_uniform, nn.init.orthogonal_]\n",
    "        )\n",
    "        torch.nn.init.constant_(getattr(rnn, 'bias_hh_l{}'.format(i)), 0)\n",
    "        \n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "        \n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "    \n",
    "\n",
    "class Tmodel(nn.Module):\n",
    "    def __init__(self,train=True):\n",
    "        super(Tmodel,self).__init__()\n",
    "        \n",
    "        SPEC_HEIGHT = 128\n",
    "        SPEC_WIDTH = 256\n",
    "        NUM_MELS = SPEC_HEIGHT\n",
    "        HOP_LENGTH = int(32000 * 5 / (SPEC_WIDTH - 1)) # sample rate * duration / spec width - 1 == 627\n",
    "        FMIN = 500\n",
    "        FMAX = 12500\n",
    "        classes_num = 398\n",
    "        self.interpolate_ratio = 8\n",
    "        \n",
    "        self.spectrogram_extractor  = Spectrogram(\n",
    "                    n_fft=2048,\n",
    "                    hop_length=HOP_LENGTH,\n",
    "                    freeze_parameters=True)\n",
    "        \n",
    "        self.logmel_extractor = LogmelFilterBank(sr=32000,\n",
    "            n_mels=NUM_MELS, fmin=FMIN, fmax=FMAX, freeze_parameters=True)\n",
    "\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "        \n",
    "        self.bn0 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # load pretrained models, using ResNeSt-50 as an example\n",
    "        if train:\n",
    "            base_model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=False)\n",
    "        else:\n",
    "            base_model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=False)\n",
    "            \n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=2048, hidden_size=1024, num_layers=1, \n",
    "            bias=True, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.att_block = AttBlockV2(2048, classes_num, activation='sigmoid')\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_gru(self.gru)\n",
    "        \n",
    "    def forward(self,input,mixup_lambda=None):\n",
    "        \n",
    "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        frames_num = x.shape[2]\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "        \n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        x = torch.tile(x,(1,3,1,1))\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x = x.transpose(1, 2)   # (batch_size, time_steps, channels)\n",
    "        (x, _) = self.gru(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        \"\"\"cla: (batch_size, classes_num, time_stpes)\"\"\"\n",
    "        \n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        interpolate_ratio = frames_num // segmentwise_output.size(1)\n",
    "        \n",
    "        # Framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "        \n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "            \n",
    "        return output_dict\n",
    "    \n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Epoch : 12 1644/3144 loss : 0.002680 / lr : 0.000095 / auto_f1_score : 0.106102 / cur_f1 : 0.134915'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cb5da04379be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Use the max. for normalizing running avg. of gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from utils.logging import Averager\n",
    "from torch.optim import lr_scheduler\n",
    "from autoth.core import ScoreCalculatorExample, HyperParamsOptimizer\n",
    "\n",
    "#learning_rate = 0.1 #for onecycle\n",
    "learning_rate = 0.001  #for cosine\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs=15\n",
    "model = Tmodel().to(torch.float32)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, \n",
    "        betas=(0.9, 0.999), eps=1e-08, weight_decay=0., amsgrad=True)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "avg = Averager()\n",
    "#scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(dataloader), epochs=epochs,\n",
    "#                                        pct_start=0.2)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dh = display('',display_id=True)\n",
    "batch_max = len(dataloader)\n",
    "loss_func = BCEFocal2WayLoss()\n",
    "\n",
    "############################\n",
    "##### auto threshold ######\n",
    "#############################\n",
    "score_calculator = ScoreCalculatorExample(dataloader.batch_size,classes_num)\n",
    "init_params = torch.Tensor([0.3]*classes_num).to(device)\n",
    "hyper_params_opt = HyperParamsOptimizer(score_calculator, \n",
    "    learning_rate=1e-2, epochs=10, step=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #train\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        wav, bird = data\n",
    "        \n",
    "        wav = torch.from_numpy(wav).to(torch.float32)\n",
    "        wav = wav.to(device)\n",
    "        \n",
    "        bird_smooth = np.where(bird==1,0.995,0.0025)\n",
    "        bird_smooth = torch.from_numpy(bird_smooth).to(torch.float32).to(device)\n",
    "        output_dict = model(wav)\n",
    "        \n",
    "        loss = loss_func(output_dict, bird_smooth)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg.add(loss)\n",
    "        if batch%20==0:\n",
    "            opt_score, init_params = hyper_params_opt.do_optimize(init_params, output_dict['clipwise_output'],\\\n",
    "                                                                  torch.from_numpy(bird).to(device))\n",
    "        dh.update('Epoch : {} {}/{} loss : {:4f} / lr : {:4f} / auto_f1_score : {:4f} / cur_f1 : {:4f}'.format(\\\n",
    "                                epoch+1,batch+1,batch_max,avg.val(),\\\n",
    "                                optimizer.param_groups[0]['lr'], opt_score,\\\n",
    "                                score_calculator(init_params,output_dict['clipwise_output'], torch.from_numpy(bird).to(device))))\n",
    "        \n",
    "        \n",
    "        del wav, bird, loss, output_dict, data\n",
    "        torch.save(model.state_dict(),os.path.join('./result/sed_auto_th.pth'))\n",
    "    #eval\n",
    "    '''\n",
    "\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from utils.logging import Averager\n",
    "from torch.optim import lr_scheduler\n",
    "from autoth.core import ScoreCalculatorExample, HyperParamsOptimizer\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "\n",
    "#learning_rate = 0.1 #for onecycle\n",
    "learning_rate = 0.001  #for cosine\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs=15\n",
    "model = Tmodel().to(torch.float32)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, \n",
    "        betas=(0.9, 0.999), eps=1e-08, weight_decay=0., amsgrad=True)\n",
    "\n",
    "saved_model = './result/sed_auto_th.pth'\n",
    "use_saved= True\n",
    "if os.path.exists(saved_model) and use_saved:\n",
    "    model.load_state_dict(torch.load(saved_model,map_location=device))\n",
    "model.to(device)    \n",
    "model.train()\n",
    "\n",
    "avg = Averager()\n",
    "f1_avg= Averager()\n",
    "#scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(dataloader), epochs=epochs,\n",
    "#                                        pct_start=0.2)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dh = display('',display_id=True)\n",
    "batch_max = len(dataloader)\n",
    "loss_func = BCEFocal2WayLoss()\n",
    "\n",
    "############################\n",
    "##### auto threshold ######\n",
    "#############################\n",
    "score_calculator = ScoreCalculatorExample(dataloader.batch_size,classes_num)\n",
    "init_params = torch.Tensor([0.3]*classes_num).to(device)\n",
    "hyper_params_opt = HyperParamsOptimizer(score_calculator, \n",
    "    learning_rate=1e-2, epochs=10, step=0.01)\n",
    "\n",
    "\n",
    "with open('./result/sed_auto_th.pkl','rb') as f:\n",
    "    init_params = pickle.load(f)\n",
    "init_params = init_params.to(torch.float).to(device)\n",
    "\n",
    "   \n",
    "opt_score = 0\n",
    "for epoch in range(epochs):\n",
    "    #train\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        wav, bird = data\n",
    "        \n",
    "        wav = torch.from_numpy(wav).to(torch.float32)\n",
    "        wav = wav.to(device)\n",
    "        \n",
    "        bird_smooth = np.where(bird==1,0.995,0.0025)\n",
    "        bird_smooth = torch.from_numpy(bird_smooth).to(torch.float32).to(device)\n",
    "        output_dict = model(wav)\n",
    "        \n",
    "        loss = loss_func(output_dict, bird_smooth)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg.add(loss)\n",
    "        with torch.no_grad():\n",
    "            if batch%20==0:\n",
    "                bef_score = opt_score\n",
    "                opt_score, init_params = hyper_params_opt.do_optimize(init_params, output_dict['clipwise_output'],\\\n",
    "                                                                      torch.from_numpy(bird).to(device))\n",
    "                if bef_score < opt_score:\n",
    "                    with open('./result/sed_auto_th.pkl','wb') as f:\n",
    "                        pickle.dump(init_params,f)\n",
    "                \n",
    "            f1 = score_calculator(init_params,output_dict['clipwise_output'], torch.from_numpy(bird).to(device))\n",
    "            f1_avg.add(f1)\n",
    "            dh.update('Epoch : {} {}/{} loss : {:4f} / lr : {:4f} / auto_f1_score : {:4f} / cur_f1 : {:4f}'.format(\\\n",
    "                                    epoch+1,batch+1,batch_max,avg.val(),\\\n",
    "                                    optimizer.param_groups[0]['lr'], opt_score,\\\n",
    "                                    f1_avg.val()))\n",
    "            \n",
    "        \n",
    "        del wav, bird, loss, output_dict, data, f1\n",
    "        torch.save(model.state_dict(),os.path.join('./result/sed_auto_th.pth'))\n",
    "        \n",
    "    #eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
